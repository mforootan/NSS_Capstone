{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.1. Calling libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should remove NANs from a list\n",
    "def cleanan(input_list):\n",
    "    cleaned = [i for i in input_list if pd.isnull(i) == False]\n",
    "    return (cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. All the CSVs created in cap_read will be called and merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_df = pd.read_csv('data/pct_rural_df.csv', index_col=1)\n",
    "rural_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "rural_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('data/pop_hous_df.csv', index_col=1)\n",
    "housing_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "housing_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_df = pd.read_csv('data/indus_dist.csv', index_col=1)\n",
    "industry_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "industry_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_df = pd.read_csv('data/density_pct.csv', index_col=1)\n",
    "density_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "density_df.rename(columns={'Hous%80-90.1' : 'Pop%80-90'},inplace=True)\n",
    "density_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm0712_df = pd.read_csv('data/farm.csv', index_col=1)\n",
    "farm0712_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "farm0712_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_sale_df = pd.read_csv('data/home_sold.csv', index_col=1)\n",
    "home_sale_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "home_sale_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm02_df = pd.read_csv('data/farm2.csv', index_col=1)\n",
    "farm02_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "farm02_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasture0712_df = pd.read_csv('data/pasture.csv', index_col=1)\n",
    "pasture0712_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "pasture0712_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasture02_df = pd.read_csv('data/pasture2.csv', index_col=1)\n",
    "pasture02_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "pasture02_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Merge the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explan_df = rural_df.merge(housing_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "explan_df = explan_df.merge(industry_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "explan_df = explan_df.merge(density_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "explan_df = explan_df.merge(home_sale_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "explan_df = explan_df.merge(farm0712_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "explan_df = explan_df.merge(pasture0712_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "explan_df = explan_df.merge(pasture02_df, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some 2007 duplicate columns are left behind, so they have to be removed\n",
    "dup_07=[]\n",
    "for i in np.arange(explan_df.shape[1]):\n",
    "    if explan_df.columns[i][-2:] =='_y':\n",
    "        dup_07.append(explan_df.columns[i])\n",
    "explan_df.drop(dup_07, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Create a list of columns\n",
    "\n",
    "This will take place separately. A file will be created in Excel, simplifying the tables PLUS adding a description to the table for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explan_cols = explan_df.transpose()\n",
    "explan_cols.isnull().sum()[explan_cols.isnull().sum() != 0]\n",
    "explan_cols['brief_header']=''\n",
    "explan_cols['description']=''\n",
    "explan_cols.drop(list(explan_cols.columns[0:95]), axis=1, inplace=True)\n",
    "# explan_cols.to_csv('data/Col_Dict2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Make a brief heading for the columns + the definition and source of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = pd.read_csv('data/Col_Dict.csv')\n",
    "col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_dict = explan_cols.merge(col_dict, left_index=True, right_on='Unnamed: 0', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_dict.drop(['brief_header_x', 'description_x'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_dict.columns = ['old','new','description','source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block renames the columns. A dictionary will describe what each column mean.\n",
    "renam=[]\n",
    "for i in np.arange(explan_df.shape[1]):\n",
    "    for j in np.arange(label_dict.shape[0]):\n",
    "        if explan_df.columns[i] == label_dict.iloc[j,0]:\n",
    "            renam.append(label_dict.iloc[j,1])\n",
    "\n",
    "explan_df.columns=renam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a test df to fill the NaNs and make sure non-NaNs are not touched\n",
    "nonan_df = explan_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block fills the NaNs with a random value from the same column.\n",
    "\n",
    "for c in np.arange(nonan_df.shape[1]):\n",
    "    uniq_val = cleanan(list(nonan_df.iloc[:,c].unique()))\n",
    "    for r in np.arange(nonan_df.shape[0]):\n",
    "        if pd.isnull(nonan_df.iloc[r,c]) == True:\n",
    "            nonan_df.iloc[r,c] = np.random.choice(uniq_val)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure no NaN value is left\n",
    "nonan_df.isnull().sum()[nonan_df.isnull().sum() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nonan_df.to_csv('data/cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Next Step: Running PCA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
